{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from beeprint import pp\n",
    "\n",
    "from models.vrnn import VRNN\n",
    "from data_apis.data_utils import SWDADataLoader\n",
    "from data_apis.SWDADialogCorpus import SWDADialogCorpus\n",
    "from utils.loss import print_loss\n",
    "import params\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    forward_only = False\n",
    "    resume = False\n",
    "    checkpoint_path = \"\"\n",
    "    test_path = \"\"\n",
    "    save_model = True\n",
    "    use_test_batch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    with open(params.api_dir, \"rb\") as fh:\n",
    "        api = pkl.load(fh, encoding='latin1')\n",
    "    dial_corpus = api.get_dialog_corpus()\n",
    "\n",
    "    train_dial, labeled_dial, test_dial = dial_corpus.get(\n",
    "        \"train\"), dial_corpus.get(\"labeled\"), dial_corpus.get(\"test\")\n",
    "\n",
    "    # convert to numeric input outputs\n",
    "    train_feed = SWDADataLoader(\"Train\", train_dial, params.max_utt_len,\n",
    "                                params.max_dialog_len)\n",
    "    valid_feed = test_feed = SWDADataLoader(\"Test\", test_dial,\n",
    "                                            params.max_utt_len,\n",
    "                                            params.max_dialog_len)\n",
    "    return train_feed, valid_feed, test_feed, np.array(api.word2vec)\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    losses = []\n",
    "    local_t = 0\n",
    "    start_time = time.time()\n",
    "    loss_names = [\"loss\"]\n",
    "    model.train()\n",
    "\n",
    "    while True:\n",
    "        optimizer.zero_grad()\n",
    "        batch = train_loader.next_batch()\n",
    "        if batch is None:\n",
    "            break\n",
    "        local_t += 1\n",
    "        loss = model(*batch)\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if local_t % (train_loader.num_batch // 10) == 0:\n",
    "            print_loss(\"%.2f\" %\n",
    "                       (train_loader.ptr / float(train_loader.num_batch)),\n",
    "                       loss_names, [losses],\n",
    "                       postfix='')\n",
    "    # finish epoch!\n",
    "    epoch_time = time.time() - start_time\n",
    "    print_loss(\"Epoch Done\", loss_names, [losses],\n",
    "               \"step time %.4f\" % (epoch_time / train_loader.num_batch))\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    losses = []\n",
    "    while True:\n",
    "        batch = valid_loader.next_batch()\n",
    "        if batch is None:\n",
    "            break\n",
    "        loss = model(*batch)\n",
    "        losses.append(loss)\n",
    "\n",
    "    print_loss(\"ELBO_VALID\", ['losses valid'], [losses], \"\")\n",
    "\n",
    "\n",
    "def decode(model, data_loader):\n",
    "    results = []\n",
    "    while True:\n",
    "        batch = data_loader.next_batch()\n",
    "        if batch is None:\n",
    "            break\n",
    "        result = model(*batch, interpret=True)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(params)\n",
    "# set random seeds\n",
    "seed = params.seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "\n",
    "# TODO: set device\n",
    "use_cuda = params.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader, valid_loader, test_loader, word2vec = get_dataset()\n",
    "\n",
    "if args.forward_only or args.resume:\n",
    "    log_dir = os.path.join(params.log_dir, args.ckpt_dir)\n",
    "    checkpoint_path = os.path.join(log_dir, args.ckpt_name)\n",
    "else:\n",
    "    log_dir = os.path.join(params.log_dir, \"run\" + str(int(time.time())))\n",
    "os.makedirs(log_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VRNN()\n",
    "# TODO: learning rate with decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=params.init_lr)\n",
    "\n",
    "if word2vec is not None and not args.forward_only:\n",
    "    print(\"Load word2vec\")\n",
    "    # TODO: trainable pretrained embedding\n",
    "    model.embedding.from_pretrained(torch.from_numpy(word2vec),\n",
    "                                    freeze=False)\n",
    "\n",
    "# Write config to a file for logging\n",
    "if not args.forward_only:\n",
    "    with open(os.path.join(log_dir, \"run.log\"), \"w\") as f:\n",
    "        f.write(pp(params, output=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = 0\n",
    "if args.resume:\n",
    "    print(\"Resuming training from %s\" % checkpoint_path)\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    last_epoch = state['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train and evaluate\n",
    "# TODO: early stop\n",
    "if not args.forward_only:\n",
    "    for epoch in range(last_epoch + 1, params.max_epoch + 1):\n",
    "        print(\">> Epoch %d with lr %f\" % (epoch, params.init_lr))\n",
    "        if train_loader.num_batch is None or train_loader.ptr >= train_loader.num_batch:\n",
    "            train_loader.epoch_init(params.batch_size, shuffle=True)\n",
    "        train(model, train_loader, optimizer)\n",
    "        valid_loader.epoch_init(params.batch_size, shuffle=False)\n",
    "        valid(model, valid_loader)\n",
    "\n",
    "        if args.save_model:\n",
    "            print(\"Save the model at the end of each epoch.\")\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state,\n",
    "                       os.path.join(log_dir, \"vrnn_\" + str(epoch) + \".pt\"))\n",
    "# Inference only\n",
    "else:\n",
    "    state = torch.load(checkpoint_path)\n",
    "    print(\"Load model from %s\" % checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    if not args.use_test_batch:\n",
    "        train_loader.epoch_init(params.batch_size, shuffle=False)\n",
    "        results = decode(model, train_loader)\n",
    "    else:\n",
    "        valid_loader.epoch_init(params.batch_size, shuffle=False)\n",
    "        results = decode(\n",
    "            model, valid_loader\n",
    "        )  # [num_batches(8), 4, batch_size(16), max_dialog_len(10), n_state(10)]\n",
    "    with open(os.path.join(log_dir, \"result.pkl\"), \"wb\") as fh:\n",
    "        pkl.dump(results, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        print(method)\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(1)\n",
    "        this_batch_size = encoder_outputs.size(0)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len))  # B x S\n",
    "\n",
    "        if params.use_cuda:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[b, :], encoder_outputs[b, i].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies, dim = 1).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            energy = torch.dot(encoder_output.view(-1), hidden.view(-1))\n",
    "            # energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            # print(\"enery size: \", energy.size())\n",
    "            # print(\"hidden size: \", hidden.size())\n",
    "            energy = torch.dot(energy.view(-1), hidden.view(-1))\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = torch.randn(16,5,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attn(\"general\", 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.randn(16, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = attn(hidden, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = attn_weights.bmm(encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
